# Identifying-Toxicity-in-User-Comments
![prblemStatementScreen](https://github.com/suman9868/Identifying-Toxicity-in-User-Comments/blob/master/additional%20screens/Problem_Statement.png)
<br />
<hr>

MOTIVATION
<br />
While interacting on online platforms, people tend to use toxic words in order to show their aggression. The aim of the project is to classify a given comment into different classes of toxicity(Toxic, Severe Toxic, Obscene, Threat, Insult and Identity Hate)
<hr>

DATASET
<br />
![DatasetTrain](https://github.com/suman9868/Identifying-Toxicity-in-User-Comments/blob/master/additional%20screens/Dataset-%20Train.PNG)
<hr>

DATA VISUALISATION
<br />
![identityHate](https://github.com/suman9868/Identifying-Toxicity-in-User-Comments/blob/master/additional%20screens/wordcloud%20-%20identity_hate.PNG)
<hr>

METHODOLOGY
<br />
![Methodology](https://github.com/suman9868/Identifying-Toxicity-in-User-Comments/blob/master/additional%20screens/methodology.png)
<hr>

RESULT
<br />
![toxicClass](https://github.com/suman9868/Identifying-Toxicity-in-User-Comments/blob/master/additional%20screens/SEVERE%20TOXIC%20CLASS.png)
<hr>
